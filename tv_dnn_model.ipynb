{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## GPU\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#cpu-gpu configuration\n",
    "#gpu_options = tf.GPUOptions(visible_device_list=\"5,6\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU':2, 'CPU':4}) #max no of GPUs = 1, CPUs =4\n",
    "#config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import ast \n",
    "import joblib\n",
    "import math\n",
    "import time\n",
    "current_t = time.time()\n",
    "from pandas import DataFrame\n",
    "from array import array\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import math\n",
    "import sklearn\n",
    "from pandas import DataFrame\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import pyodbc\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from termcolor import colored\n",
    "from sklearn.metrics import classification_report\n",
    "from multiprocessing import Pool\n",
    "from timeit import default_timer as timer\n",
    "from math import sqrt\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") #Needed to save figures\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "import json\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize, CascadeClassifier\n",
    "import glob\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import time, sys\n",
    "from tkinter import font\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import keras models for Neural Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Activation, add, Dense, Flatten, Dropout, Multiply, Embedding, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D,PReLU\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import theano\n",
    "from keras.layers import Dense, Convolution2D, UpSampling2D, MaxPooling2D, ZeroPadding2D, Flatten, Dropout, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils import Sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, Input, Masking, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data files and append to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "path = r'/mnt/sde/jagadish/userdata/dl_project/tv_train_files/' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    dd = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(dd)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.drop(columns=df.columns[0])\n",
    "df = df.drop(columns='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(df.filter(regex = 'fd')), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(\"/mnt/sde/jagadish/userdata/dl_project/tv_test_data/tv_8307.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = gf.drop(columns=gf.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.drop(list(gf.filter(regex = 'fd')), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_label(data):\n",
    "    # remove outliers\n",
    "    #data_after = data[(data['price']<400) & (data['price']>1)]\n",
    "    #data_after = data[data['price']>1]\n",
    "    # split features and labels\n",
    "    #train_features = data.drop(['responded'],axis=1)\n",
    "    train_features = data.drop(['Y'],axis=1)\n",
    "    train_labels = data.Y\n",
    "    return train_features,train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features,train_labels=get_feature_label(df)\n",
    "train_features=train_features\n",
    "train_labels=train_labels\n",
    "test_features,test_labels=get_feature_label(gf)\n",
    "test_features=test_features\n",
    "test_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features\n",
    "y = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = scaler.transform(test_features)\n",
    "test_features = pd.DataFrame(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.001)\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "ada =optimizers.Adadelta(lr=0.0001, rho = 0.95, epsilon = 1e-07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_t = time.time()\n",
    "\n",
    "verbose, epochs, batch_size = 1, 1200, 15\n",
    "n_features, n_outputs = 720, 1\n",
    "# define model\n",
    "model = Sequential()\n",
    "#kernel_regularizer=regularizers.l2(0.01),\n",
    "#model.add(LSTM(500, activation='relu',return_sequences=False, input_shape=(n_samples, n_features)))\n",
    "model.add(Dense(200, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.001), input_shape=(n_features,)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='Adam')\n",
    "model.summary()\n",
    "# fit network\n",
    "history = model.fit(X, y, epochs=epochs, batch_size=batch_size,validation_split=0.0, verbose=verbose)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model.save('tv_model.h5')  # creates a HDF5 file 'tv_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('tv_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# #acc = history.history['acc']\n",
    "# #val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "# plt.savefig('Watching_TV_train_val_loss_curve.jpg')  # saves the current figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plt.plot(epochs, acc, 'go', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'g', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "# plt.savefig('Watching_TV_train_val_accuracy_curve.jpg')  # saves the current figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = model.predict(test_features, verbose=0)\n",
    "results = y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results<=0.5]=0\n",
    "results[results>0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = results\n",
    "y_true = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = format(accuracy_score(y_true, y_pred),'.4f')\n",
    "\n",
    "\n",
    "sensitivity = format(recall_score(y_true, y_pred,pos_label=1,average='binary'),'.4f')\n",
    "\n",
    "specificity = format(recall_score(y_true, y_pred,pos_label=0,average='binary'),'.4f')\n",
    "\n",
    "print('Accuracy : ', accuracy)   \n",
    "print('Sensitivity : ', sensitivity)\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Features_extraction complete. Time elapsed: \" + str(int(time.time()-current_t )) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save JSON file with time and label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = pd.DataFrame(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = pd.DataFrame(columns=['Watching_TV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoFile = \"/mnt/sde/jagadish/userdata/IMG_8307.MOV\"\n",
    "cap = cv.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "fps = cap.get(cv.CAP_PROP_FPS) # Getting Franme rate of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= hf.index\n",
    "l=[]\n",
    "c=0\n",
    "for i in n[:] :\n",
    "    \n",
    "    l.append(c/fps)\n",
    "    l.append(hf.iloc[i][0])\n",
    "    \n",
    "    mf = mf.append({'Watching_TV':l[:]}, ignore_index=True)\n",
    "    l=[]\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.to_json('Time_and_Label_8307_.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and save \"Time vs Label\" graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.DataFrame(columns=['Time', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= hf.index\n",
    "c=0\n",
    "for i in n[:] :\n",
    "    \n",
    "\n",
    "    \n",
    "    pf = pf.append({'Time': c/fps, 'Label': hf.iloc[i][0]}, ignore_index=True)\n",
    "\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pf['Time']\n",
    "label1 = pf['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(time, label1, 'g')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xticks(fontsize=20, fontweight='bold',rotation=90)\n",
    "plt.yticks(fontsize=20, fontweight='bold')\n",
    "plt.xlabel('Time (seconds)',fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Label',fontsize=20, fontweight='bold')\n",
    "plt.title('Time vs Label', fontsize=20, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "#plt.legend()\n",
    "plt.savefig('Time_and_Labels_8307_.pdf')  # saves the current figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
